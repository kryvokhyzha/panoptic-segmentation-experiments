{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "## install deps"
   ],
   "metadata": {
    "id": "i5Y26VvYbd0N"
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "T9KpLHEqqRFi",
    "outputId": "ff2c8098-1542-4d8d-c6ff-6d39586a1cf2"
   },
   "outputs": [],
   "source": [
    "!pip install -qq -U openmim==0.3.9\n",
    "# !pip install -qq -U mmdet==3.2.0\n",
    "!mim install -qq mmengine\n",
    "!mim install -qq \"mmcv>=2.0.0\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "p6asGFghrX-L",
    "outputId": "9250a1dc-ce8f-4223-c9fa-b7e38afe0943"
   },
   "outputs": [],
   "source": [
    "!git clone https://github.com/open-mmlab/mmdetection.git\n",
    "%cd mmdetection\n",
    "!pip install -qq -v -e .\n",
    "%cd /content"
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "!pip install -qq git+https://github.com/cocodataset/panopticapi.git"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "33j-Rp5xpO7W",
    "outputId": "9100d7c0-97d7-4579-c314-e0e5b4c41aab"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "## download rtdet config and weights"
   ],
   "metadata": {
    "id": "ax4v4JEobhcs"
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "9B54PPWOt-3b",
    "outputId": "f1d6dbca-9354-4c26-e0ef-9d0a7f2f3042"
   },
   "outputs": [],
   "source": [
    "!mim download mmdet --config rtmdet_tiny_8xb32-300e_coco --dest ."
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "## run test detection"
   ],
   "metadata": {
    "id": "ytSCsk6zblSz"
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "I_jlLALouOSu",
    "outputId": "f1f8fcef-c771-40e2-8f69-b66ddb607b17"
   },
   "outputs": [],
   "source": [
    "!python mmdetection/demo/image_demo.py \\\n",
    "        mmdetection/demo/demo.jpg \\\n",
    "        rtmdet_tiny_8xb32-300e_coco.py \\\n",
    "        --weights rtmdet_tiny_8xb32-300e_coco_20220902_112414-78e30dcc.pth \\\n",
    "        --device cpu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 462
    },
    "id": "6ksHRA_6uujT",
    "outputId": "ed59961a-09ac-4314-ba26-f28de57525d5"
   },
   "outputs": [],
   "source": [
    "%cd outputs/vis\n",
    "from IPython.display import Image\n",
    "\n",
    "\n",
    "display(Image(\"demo.jpg\"))\n",
    "%cd /content"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "## download cityscapes dataset"
   ],
   "metadata": {
    "id": "yAOas_sibolN"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "import gdown"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "oH6B-cnPoDhN",
    "outputId": "ea47780d-4735-4de7-a93e-430555b242f2"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "def download_from_colab(file_id: str):\n",
    "    output_file = \"cityscapes.zip\"\n",
    "    url = f\"https://drive.google.com/uc?id={file_id}\"\n",
    "    gdown.download(url, output_file, quiet=True)"
   ],
   "metadata": {
    "id": "ShCZ_vIYn99w"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "%cd /content\n",
    "%rm -rf data\n",
    "%rm -rf cityscapes"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "xZJLiJi7Du0E",
    "outputId": "2305197a-1810-4354-f6f4-e92614decd7f"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "download_from_colab(\"1PMPMfEKWK0kvwadQAtvcrEY1SDTYvRgt\")\n",
    "\n",
    "!mkdir -p data\n",
    "!unzip -qq -o cityscapes.zip -d /content/data/cityscapes\n",
    "!rm cityscapes.zip"
   ],
   "metadata": {
    "id": "YjqsQo15QbE4"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "download_from_colab(\"1eUn338xKhhmJ6ykfWu0_CAwVMLZ7aFx1\")\n",
    "\n",
    "!mkdir -p data\n",
    "!unzip -qq -o cityscapes.zip -d /content/data/cityscapes\n",
    "!rm cityscapes.zip"
   ],
   "metadata": {
    "id": "u9Tfs4aHKMuk"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "## convert cityscapes to coco"
   ],
   "metadata": {
    "id": "onON7zqCbsBy"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "%cd /content\n",
    "%mkdir -p scripts"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Wyt4vPsnwEnD",
    "outputId": "81ccf269-66f5-47c7-a2f4-21bde8815176"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "!pip install -qq tqdm fire cityscapesscripts"
   ],
   "metadata": {
    "id": "1KCVyNl9wqcJ"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "%%writefile scripts/convert_cityscapes_to_coco_panoptic.py\n",
    "import os\n",
    "import fire\n",
    "import json\n",
    "import glob\n",
    "import numpy as np\n",
    "import shutil\n",
    "import PIL.Image as Image\n",
    "\n",
    "from tqdm import tqdm\n",
    "from joblib import Parallel, delayed\n",
    "from panopticapi.utils import IdGenerator\n",
    "\n",
    "\n",
    "try:\n",
    "    # set up path for cityscapes scripts\n",
    "    # sys.path.append('./cityscapesScripts/')\n",
    "    from cityscapesscripts.helpers.labels import labels, id2label\n",
    "except Exception:\n",
    "    raise Exception(\"Please load Cityscapes scripts from https://github.com/mcordts/cityscapesScripts\")\n",
    "\n",
    "\n",
    "class NpEncoder(json.JSONEncoder):\n",
    "    def default(self, obj):\n",
    "        if isinstance(obj, np.integer):\n",
    "            return int(obj)\n",
    "        if isinstance(obj, np.floating):\n",
    "            return float(obj)\n",
    "        if isinstance(obj, np.ndarray):\n",
    "            return obj.tolist()\n",
    "        return super(NpEncoder, self).default(obj)\n",
    "\n",
    "\n",
    "def image_converter(f, categories_dict, out_folder):\n",
    "    original_format = np.array(Image.open(f))\n",
    "\n",
    "    file_name = f.split('/')[-1]\n",
    "    image_id = '_'.join(file_name.split('_')[:3])\n",
    "    image_filename = '{}.png'.format(image_id)\n",
    "    segm_filename = '{}.png'.format(image_id)\n",
    "\n",
    "    # image entry, id for image is its filename without extension\n",
    "    image_config = {\n",
    "        \"id\": image_id,\n",
    "        \"width\": original_format.shape[1],\n",
    "        \"height\": original_format.shape[0],\n",
    "        \"file_name\": image_filename\n",
    "    }\n",
    "\n",
    "    pan_format = np.zeros((original_format.shape[0], original_format.shape[1], 3), dtype=np.uint8)\n",
    "    id_generator = IdGenerator(categories_dict)\n",
    "\n",
    "    l = np.unique(original_format)\n",
    "    segm_info = []\n",
    "    for el in l:\n",
    "        if el < 1000:\n",
    "            semantic_id = el\n",
    "            is_crowd = 1\n",
    "        else:\n",
    "            semantic_id = el // 1000\n",
    "            is_crowd = 0\n",
    "        if semantic_id not in categories_dict:\n",
    "            continue\n",
    "        if categories_dict[semantic_id]['isthing'] == 0:\n",
    "            is_crowd = 0\n",
    "        mask = original_format == el\n",
    "        segment_id, color = id_generator.get_id_and_color(semantic_id)\n",
    "        pan_format[mask] = color\n",
    "\n",
    "        area = np.sum(mask)  # segment area computation\n",
    "\n",
    "        # bbox computation for a segment\n",
    "        hor = np.sum(mask, axis=0)\n",
    "        hor_idx = np.nonzero(hor)[0]\n",
    "        x = hor_idx[0]\n",
    "        width = hor_idx[-1] - x + 1\n",
    "        vert = np.sum(mask, axis=1)\n",
    "        vert_idx = np.nonzero(vert)[0]\n",
    "        y = vert_idx[0]\n",
    "        height = vert_idx[-1] - y + 1\n",
    "        bbox = [x, y, width, height]\n",
    "\n",
    "        segm_info.append({\n",
    "            \"id\": int(segment_id),\n",
    "            \"category_id\": int(semantic_id),\n",
    "            \"area\": area,\n",
    "            \"bbox\": bbox,\n",
    "            \"iscrowd\": is_crowd,\n",
    "        })\n",
    "\n",
    "    annotation_config = {\n",
    "        'image_id': image_id,\n",
    "        'file_name': segm_filename,\n",
    "        \"segments_info\": segm_info,\n",
    "    }\n",
    "\n",
    "    Image.fromarray(pan_format).save(os.path.join(out_folder, segm_filename))\n",
    "    return image_config, annotation_config\n",
    "\n",
    "\n",
    "def panoptic_converter(\n",
    "        gt_folder_path: str,\n",
    "        gt_output_folder_path: str,\n",
    "        gt_output_annotations_file_path: str,\n",
    "        img_folder_path: str,\n",
    "        img_output_folder_path: str,\n",
    "        n_jobs: int = 4,\n",
    "        remove_folders: bool = False,\n",
    "):\n",
    "\n",
    "    if not os.path.isdir(gt_output_folder_path):\n",
    "        print(\"Creating folder {} for panoptic segmentation GT PNGs\".format(gt_output_folder_path))\n",
    "        os.mkdir(gt_output_folder_path)\n",
    "\n",
    "    if not os.path.isdir(img_output_folder_path):\n",
    "        print(\"Creating folder {} for panoptic segmentation 8-bit PNGs\".format(img_output_folder_path))\n",
    "        os.mkdir(img_output_folder_path)\n",
    "\n",
    "    categories = []\n",
    "    for idx, el in tqdm(enumerate(labels), total=len(labels), desc='Adding categories'):\n",
    "        if el.ignoreInEval:\n",
    "            continue\n",
    "\n",
    "        categories.append({\n",
    "            'id': el.id,\n",
    "            'name': el.name,\n",
    "            'color': el.color,\n",
    "            'supercategory': el.category,\n",
    "            'isthing': 1 if el.hasInstances else 0\n",
    "        })\n",
    "\n",
    "    categories_dict = {cat['id']: cat for cat in categories}\n",
    "\n",
    "    gt_file_list = sorted(glob.glob(os.path.join(gt_folder_path, '*/*_gtFine_instanceIds.png')))\n",
    "\n",
    "    result = Parallel(n_jobs=n_jobs, return_as=\"list\")(\n",
    "        delayed(image_converter)(f, categories_dict, gt_output_folder_path)\n",
    "        for f in tqdm(gt_file_list, total=len(gt_file_list), desc='Converting images')\n",
    "    )\n",
    "    images, annotations = list(zip(*result))\n",
    "\n",
    "    d = {\n",
    "        'images': images,\n",
    "        'annotations': annotations,\n",
    "        'categories': categories,\n",
    "    }\n",
    "\n",
    "    with open(gt_output_annotations_file_path, 'w') as f:\n",
    "        json.dump(d, f, cls=NpEncoder)\n",
    "\n",
    "    if remove_folders:\n",
    "        shutil.rmtree(gt_folder_path)\n",
    "\n",
    "    img_file_list = sorted(glob.glob(os.path.join(img_folder_path, '*/*_leftImg8bit.png')))\n",
    "    Parallel(n_jobs=n_jobs, return_as=\"list\")(\n",
    "        delayed(shutil.copyfile)(\n",
    "            f,\n",
    "            os.path.join(img_output_folder_path, f\"{'_'.join(f.split('/')[-1].split('_')[:3])}.png\")\n",
    "        )\n",
    "        for f in tqdm(img_file_list, total=len(img_file_list), desc='Move 8-bit images')\n",
    "    )\n",
    "\n",
    "    if remove_folders:\n",
    "        shutil.rmtree(img_folder_path)\n",
    "\n",
    "\n",
    "fire.Fire(panoptic_converter)\n"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "lBBLJga8v-HN",
    "outputId": "d2e103d6-8c5a-4fe5-f945-92b837c7e034"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "!mkdir -p data/cityscapes/annotations && \\\n",
    "python scripts/convert_cityscapes_to_coco_panoptic.py \\\n",
    "        --gt_folder_path=data/cityscapes/gtFine/test/ \\\n",
    "        --gt_output_folder_path=data/cityscapes/gtFine/cityscapes_panoptic_test/ \\\n",
    "        --gt_output_annotations_file_path=data/cityscapes/annotations/cityscapes_panoptic_test.json \\\n",
    "        --img_folder_path=data/cityscapes/leftImg8bit/test \\\n",
    "        --img_output_folder_path=data/cityscapes/leftImg8bit/cityscapes_panoptic_test \\\n",
    "        --n_jobs=6 && \\\n",
    "python scripts/convert_cityscapes_to_coco_panoptic.py \\\n",
    "        --gt_folder_path=data/cityscapes/gtFine/val/ \\\n",
    "        --gt_output_folder_path=data/cityscapes/gtFine/cityscapes_panoptic_val/ \\\n",
    "        --gt_output_annotations_file_path=data/cityscapes/annotations/cityscapes_panoptic_val.json \\\n",
    "        --img_folder_path=data/cityscapes/leftImg8bit/val \\\n",
    "        --img_output_folder_path=data/cityscapes/leftImg8bit/cityscapes_panoptic_val \\\n",
    "        --n_jobs=6 && \\\n",
    "python scripts/convert_cityscapes_to_coco_panoptic.py \\\n",
    "        --gt_folder_path=data/cityscapes/gtFine/train/ \\\n",
    "        --gt_output_folder_path=data/cityscapes/gtFine/cityscapes_panoptic_train/ \\\n",
    "        --gt_output_annotations_file_path=data/cityscapes/annotations/cityscapes_panoptic_train.json \\\n",
    "        --img_folder_path=data/cityscapes/leftImg8bit/train \\\n",
    "        --img_output_folder_path=data/cityscapes/leftImg8bit/cityscapes_panoptic_train \\\n",
    "        --n_jobs=6"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "LxqznN_GwaZI",
    "outputId": "e58ea9fb-d2e0-4cfd-825b-2181328e8f08"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "!head -c 250 data/cityscapes/annotations/cityscapes_panoptic_train.json"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "cpSfZuOEBTmQ",
    "outputId": "44cfdabe-337e-4e83-d66d-d6a63ee287a9"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "## download mask2former (coco and panoptic coco)"
   ],
   "metadata": {
    "id": "unX1Ppoxbwak"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "%cd /content\n",
    "!mim download mmdet --config mask2former_r50_8xb2-lsj-50e_coco-panoptic --dest .\n",
    "!mim download mmdet --config mask2former_r50_8xb2-lsj-50e_coco --dest ."
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "1i7-_zH3M1vm",
    "outputId": "0f8f6508-9cf6-4085-cd15-84724a65cfb7"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "## run test segmentation mask2former coco"
   ],
   "metadata": {
    "id": "WKHt0zBIb16m"
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "s7y6i7QWyyiP",
    "outputId": "3109ce2e-5bc9-4ada-d8bb-a96a0cbaab38"
   },
   "outputs": [],
   "source": [
    "!python mmdetection/demo/image_demo.py \\\n",
    "        mmdetection/demo/demo.jpg \\\n",
    "        mask2former_r50_8xb2-lsj-50e_coco.py \\\n",
    "        --weights mask2former_r50_8xb2-lsj-50e_coco_20220506_191028-41b088b6.pth \\\n",
    "        --device cpu"
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "from IPython.display import Image\n",
    "\n",
    "\n",
    "Image(\"outputs/vis/demo.jpg\")"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 444
    },
    "id": "JEZ5Zkn9NuKN",
    "outputId": "a896e0e1-59d5-4d52-c2a9-af8c84be14e3"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "## run test panoptic segmentation mask2former coco"
   ],
   "metadata": {
    "id": "f7yXHtftb6tk"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "!python mmdetection/demo/image_demo.py \\\n",
    "        mmdetection/demo/demo.jpg \\\n",
    "        mask2former_r50_8xb2-lsj-50e_coco-panoptic.py \\\n",
    "        --weights mask2former_r50_8xb2-lsj-50e_coco-panoptic_20230118_125535-54df384a.pth \\\n",
    "        --device cpu"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "N6Qivy7ZOaAi",
    "outputId": "5b7b57e5-cc4d-402f-eb52-86e8e9fd3828"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "from IPython.display import Image\n",
    "\n",
    "\n",
    "Image(\"outputs/vis/demo.jpg\")"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 444
    },
    "id": "2LHZ2jMPPAWn",
    "outputId": "952fbb73-98dc-43be-f0c9-fb70bd63942f"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "## run test segmentation on one image from cityscapes"
   ],
   "metadata": {
    "id": "khaXpNCVb9t_"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### CLI"
   ],
   "metadata": {
    "id": "wn_bU2_cDtgb"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "!python mmdetection/demo/image_demo.py \\\n",
    "        /content/data/cityscapes/leftImg8bit/train/krefeld/krefeld_000000_000108_leftImg8bit.png \\\n",
    "        mask2former_r50_8xb2-lsj-50e_coco-panoptic.py \\\n",
    "        --weights mask2former_r50_8xb2-lsj-50e_coco-panoptic_20230118_125535-54df384a.pth \\\n",
    "        --device cpu"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "FI4CEhcgcC3I",
    "outputId": "f90dfcfc-8e66-4e58-9e07-d561a6139e9c"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "from IPython.display import Image\n",
    "\n",
    "\n",
    "Image(\"outputs/vis/demo.jpg\")"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 444
    },
    "id": "QiNek2OxDzDL",
    "outputId": "fad10d94-83db-4013-f18a-9c1aaebea877"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "Python SDK"
   ],
   "metadata": {
    "id": "6Ux_JmEBDvDZ"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "%cd /content/mmdetection\n",
    "from mmdet.apis import DetInferencer\n",
    "\n",
    "\n",
    "# Initialize the DetInferencer\n",
    "inferencer = DetInferencer(\"mask2former_r50_8xb2-lsj-50e_coco-panoptic\")\n",
    "\n",
    "# Perform inference\n",
    "inf_result = inferencer(\n",
    "    \"/content/data/cityscapes/leftImg8bit/train/krefeld/krefeld_000000_000108_leftImg8bit.png\",\n",
    "    return_vis=True,\n",
    "    out_dir=\"./outputs\",\n",
    ")\n",
    "%cd /content"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 143,
     "referenced_widgets": [
      "74044288d8584b2aa53f93c507ffe615",
      "619f1b131b6041ca91ed77504396de37"
     ]
    },
    "id": "Tr9aj-XZcC0F",
    "outputId": "8a4b1bbb-8884-454d-c220-4f10a434080d"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "inf_result.keys()"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "jvf3Yp9Ne2LB",
    "outputId": "4d81482c-5f4f-4b1c-bd30-9004bece8bb8"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "inf_result[\"predictions\"][0].keys()"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "uWYlUfZvfm0t",
    "outputId": "1fd3eb42-f6fa-45b5-98e1-76259be33030"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "inf_result[\"predictions\"][0][\"panoptic_seg\"]"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "bhePse9Lkune",
    "outputId": "425476f1-93ec-4030-e9db-d9d665f978dc"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "inf_result[\"predictions\"][0][\"masks\"][0]"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "9gR2Rem5q4oi",
    "outputId": "23c55796-244f-4f00-cba8-bb884ba98192"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "from matplotlib import cm\n",
    "from PIL import Image\n",
    "\n",
    "\n",
    "im = Image.fromarray(inf_result[\"visualization\"][0])\n",
    "display(im)"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 559
    },
    "id": "UCuhDztYe8w-",
    "outputId": "ba91bd51-21e8-461d-b564-78fdccadeab5"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "# from panopticapi import evaluation\n",
    "\n",
    "# evaluation.pq_compute(\n",
    "#     gt_json_file='/content/data/cityscapes/annotations/instancesonly_filtered_gtFine_train.json',\n",
    "#     pred_json_file='',\n",
    "# )"
   ],
   "metadata": {
    "id": "cO9Ixv-uqJ0v"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Infer one image and compute metrics using torchmetrics"
   ],
   "metadata": {
    "id": "nsofKBY6pEpU"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "# !pip install -qq torchmetrics==1.2.1"
   ],
   "metadata": {
    "id": "oOmMyymhDmRK"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "# from torch import tensor\n",
    "\n",
    "# preds = tensor([[[[6, 0], [0, 0], [6, 0], [6, 0]],\n",
    "#                  [[0, 0], [0, 0], [6, 0], [0, 1]],\n",
    "#                  [[0, 0], [0, 0], [6, 0], [0, 1]],\n",
    "#                  [[0, 0], [7, 0], [6, 0], [1, 0]],\n",
    "#                  [[0, 0], [7, 0], [7, 0], [7, 0]]]])\n",
    "# target = tensor([[[[6, 0], [0, 1], [6, 0], [0, 1]],\n",
    "#                   [[0, 1], [0, 1], [6, 0], [0, 1]],\n",
    "#                   [[0, 1], [0, 1], [6, 0], [1, 0]],\n",
    "#                   [[0, 1], [7, 0], [1, 0], [1, 0]],\n",
    "#                   [[0, 1], [7, 0], [7, 0], [7, 0]]]])\n",
    "\n",
    "# print(preds.shape, target.shape)"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "paSBiN-cjCbG",
    "outputId": "51d3858f-8c20-4a34-b3da-34ce9030c02d"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "# from torchmetrics.detection import PanopticQuality\n",
    "\n",
    "# metric = PanopticQuality(things = {0, 1}, stuffs = {6, 7})\n",
    "# metric.update(preds, target)\n",
    "# fig_, ax_ = metric.plot()"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 375
    },
    "id": "vIbLabDdcCw5",
    "outputId": "179fc7ff-88ad-408d-8d91-58d3db173821"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "from IPython.display import Image\n",
    "\n",
    "\n",
    "Image(\"/content/data/cityscapes/gtFine/train/krefeld/krefeld_000000_000108_gtFine_color.png\")"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 559
    },
    "id": "97XxMfMscCtE",
    "outputId": "0f966d81-7379-402a-ece5-5ecbabf8a6a8"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "## train mask2former on cityscapes dataset"
   ],
   "metadata": {
    "id": "TUyrPCvzzbqp"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "%cd /content/\n",
    "%rm -rf work_dirs"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "aIIDgZ9k7rps",
    "outputId": "c9ec2a2a-f768-4554-9352-322bad2e676f"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "%%writefile mask2former_r50_8xb2-lsj-50e_cityscapes-panoptic_train.py\n",
    "auto_scale_lr = dict(base_batch_size=16, enable=False)  # base_batch_size=16\n",
    "backend_args = None\n",
    "batch_augments = [\n",
    "    dict(\n",
    "        img_pad_value=0,\n",
    "        mask_pad_value=0,\n",
    "        pad_mask=True,\n",
    "        pad_seg=True,\n",
    "        seg_pad_value=255,\n",
    "        size=(\n",
    "            1024,\n",
    "            1024,\n",
    "        ),\n",
    "        type='BatchFixedSizePad'),\n",
    "]\n",
    "data_preprocessor = dict(\n",
    "    batch_augments=[\n",
    "        dict(\n",
    "            img_pad_value=0,\n",
    "            mask_pad_value=0,\n",
    "            pad_mask=True,\n",
    "            pad_seg=True,\n",
    "            seg_pad_value=255,\n",
    "            size=(\n",
    "                1024,\n",
    "                1024,\n",
    "            ),\n",
    "            type='BatchFixedSizePad'),\n",
    "    ],\n",
    "    bgr_to_rgb=True,\n",
    "    mask_pad_value=0,\n",
    "    mean=[\n",
    "        123.675,\n",
    "        116.28,\n",
    "        103.53,\n",
    "    ],\n",
    "    pad_mask=True,\n",
    "    pad_seg=True,\n",
    "    pad_size_divisor=32,\n",
    "    seg_pad_value=255,\n",
    "    std=[\n",
    "        58.395,\n",
    "        57.12,\n",
    "        57.375,\n",
    "    ],\n",
    "    type='DetDataPreprocessor')\n",
    "data_root = './data/cityscapes/'\n",
    "dataset_type = 'CityscapesPanopticDataset'\n",
    "default_hooks = dict(\n",
    "    checkpoint=dict(\n",
    "        by_epoch=False,\n",
    "        interval=5000,\n",
    "        max_keep_ckpts=3,\n",
    "        save_last=True,\n",
    "        type='CheckpointHook'),\n",
    "    logger=dict(interval=50, type='LoggerHook'),\n",
    "    param_scheduler=dict(type='ParamSchedulerHook'),\n",
    "    sampler_seed=dict(type='DistSamplerSeedHook'),\n",
    "    timer=dict(type='IterTimerHook'),\n",
    "    visualization=dict(type='DetVisualizationHook'))\n",
    "default_scope = 'mmdet'\n",
    "dynamic_intervals = [\n",
    "    (\n",
    "        365001,\n",
    "        368750,\n",
    "    ),\n",
    "]\n",
    "embed_multi = dict(decay_mult=0.0, lr_mult=1.0)\n",
    "env_cfg = dict(\n",
    "    cudnn_benchmark=False,\n",
    "    dist_cfg=dict(backend='nccl'),\n",
    "    mp_cfg=dict(mp_start_method='fork', opencv_num_threads=0))\n",
    "image_size = (\n",
    "    1024,\n",
    "    1024,\n",
    ")\n",
    "interval = 5000\n",
    "load_from = None\n",
    "log_level = 'INFO'\n",
    "log_processor = dict(by_epoch=False, type='LogProcessor', window_size=50)\n",
    "max_iters = 368750\n",
    "model = dict(\n",
    "    backbone=dict(\n",
    "        depth=50,\n",
    "        frozen_stages=-1,\n",
    "        init_cfg=dict(checkpoint='torchvision://resnet50', type='Pretrained'),\n",
    "        norm_cfg=dict(requires_grad=False, type='BN'),\n",
    "        norm_eval=True,\n",
    "        num_stages=4,\n",
    "        out_indices=(\n",
    "            0,\n",
    "            1,\n",
    "            2,\n",
    "            3,\n",
    "        ),\n",
    "        style='pytorch',\n",
    "        type='ResNet'),\n",
    "    data_preprocessor=dict(\n",
    "        batch_augments=[\n",
    "            dict(\n",
    "                img_pad_value=0,\n",
    "                mask_pad_value=0,\n",
    "                pad_mask=True,\n",
    "                pad_seg=True,\n",
    "                seg_pad_value=255,\n",
    "                size=(\n",
    "                    1024,\n",
    "                    1024,\n",
    "                ),\n",
    "                type='BatchFixedSizePad'),\n",
    "        ],\n",
    "        bgr_to_rgb=True,\n",
    "        mask_pad_value=0,\n",
    "        mean=[\n",
    "            123.675,\n",
    "            116.28,\n",
    "            103.53,\n",
    "        ],\n",
    "        pad_mask=True,\n",
    "        pad_seg=True,\n",
    "        pad_size_divisor=32,\n",
    "        seg_pad_value=255,\n",
    "        std=[\n",
    "            58.395,\n",
    "            57.12,\n",
    "            57.375,\n",
    "        ],\n",
    "        type='DetDataPreprocessor'),\n",
    "    init_cfg=None,\n",
    "    panoptic_fusion_head=dict(\n",
    "        init_cfg=None,\n",
    "        loss_panoptic=None,\n",
    "        num_stuff_classes=21,#53\n",
    "        num_things_classes=14,#80\n",
    "        type='MaskFormerFusionHead'),\n",
    "    panoptic_head=dict(\n",
    "        enforce_decoder_input_project=False,\n",
    "        feat_channels=256,\n",
    "        in_channels=[\n",
    "            256,\n",
    "            512,\n",
    "            1024,\n",
    "            2048,\n",
    "        ],\n",
    "        loss_cls=dict(\n",
    "            class_weight=[\n",
    "                1.0,\n",
    "                1.0,\n",
    "                1.0,\n",
    "                1.0,\n",
    "                1.0,\n",
    "                1.0,\n",
    "                1.0,\n",
    "                1.0,\n",
    "                1.0,\n",
    "                1.0,\n",
    "                1.0,\n",
    "                1.0,\n",
    "                1.0,\n",
    "                1.0,\n",
    "                1.0,\n",
    "                1.0,\n",
    "                1.0,\n",
    "                1.0,\n",
    "                1.0,\n",
    "                1.0,\n",
    "                1.0,\n",
    "                1.0,\n",
    "                1.0,\n",
    "                1.0,\n",
    "                1.0,\n",
    "                1.0,\n",
    "                1.0,\n",
    "                1.0,\n",
    "                1.0,\n",
    "                1.0,\n",
    "                1.0,\n",
    "                1.0,\n",
    "                1.0,\n",
    "                1.0,\n",
    "                1.0,\n",
    "                0.1,\n",
    "\n",
    "                # 1.0,\n",
    "                # 1.0,\n",
    "                # 1.0,\n",
    "                # 1.0,\n",
    "                # 1.0,\n",
    "                # 1.0,\n",
    "                # 1.0,\n",
    "                # 1.0,\n",
    "                # 1.0,\n",
    "                # 1.0,\n",
    "                # 1.0,\n",
    "                # 1.0,\n",
    "                # 1.0,\n",
    "                # 1.0,\n",
    "                # 1.0,\n",
    "                # 1.0,\n",
    "                # 1.0,\n",
    "                # 1.0,\n",
    "                # 1.0,\n",
    "                # 1.0,\n",
    "                # 1.0,\n",
    "                # 1.0,\n",
    "                # 1.0,\n",
    "                # 1.0,\n",
    "                # 1.0,\n",
    "                # 1.0,\n",
    "                # 1.0,\n",
    "                # 1.0,\n",
    "                # 1.0,\n",
    "                # 1.0,\n",
    "                # 1.0,\n",
    "                # 1.0,\n",
    "                # 1.0,\n",
    "                # 1.0,\n",
    "                # 1.0,\n",
    "                # 1.0,\n",
    "                # 1.0,\n",
    "                # 1.0,\n",
    "                # 1.0,\n",
    "                # 1.0,\n",
    "                # 1.0,\n",
    "                # 1.0,\n",
    "                # 1.0,\n",
    "                # 1.0,\n",
    "                # 1.0,\n",
    "                # 1.0,\n",
    "                # 1.0,\n",
    "                # 1.0,\n",
    "                # 1.0,\n",
    "                # 1.0,\n",
    "                # 1.0,\n",
    "                # 1.0,\n",
    "                # 1.0,\n",
    "                # 1.0,\n",
    "                # 1.0,\n",
    "                # 1.0,\n",
    "                # 1.0,\n",
    "                # 1.0,\n",
    "                # 1.0,\n",
    "                # 1.0,\n",
    "                # 1.0,\n",
    "                # 1.0,\n",
    "                # 1.0,\n",
    "                # 1.0,\n",
    "                # 1.0,\n",
    "                # 1.0,\n",
    "                # 1.0,\n",
    "                # 1.0,\n",
    "                # 1.0,\n",
    "                # 1.0,\n",
    "                # 1.0,\n",
    "                # 1.0,\n",
    "                # 1.0,\n",
    "                # 1.0,\n",
    "                # 1.0,\n",
    "                # 1.0,\n",
    "                # 1.0,\n",
    "                # 1.0,\n",
    "                # 1.0,\n",
    "                # 1.0,\n",
    "                # 1.0,\n",
    "                # 1.0,\n",
    "                # 1.0,\n",
    "                # 1.0,\n",
    "                # 1.0,\n",
    "                # 1.0,\n",
    "                # 1.0,\n",
    "                # 1.0,\n",
    "                # 1.0,\n",
    "                # 1.0,\n",
    "                # 1.0,\n",
    "                # 1.0,\n",
    "                # 1.0,\n",
    "                # 1.0,\n",
    "                # 1.0,\n",
    "                # 1.0,\n",
    "                # 1.0,\n",
    "                # 1.0,\n",
    "                # 1.0,\n",
    "                # 1.0,\n",
    "                # 1.0,\n",
    "                # 1.0,\n",
    "                # 1.0,\n",
    "                # 1.0,\n",
    "                # 1.0,\n",
    "                # 1.0,\n",
    "                # 1.0,\n",
    "                # 1.0,\n",
    "                # 1.0,\n",
    "                # 1.0,\n",
    "                # 1.0,\n",
    "                # 1.0,\n",
    "                # 1.0,\n",
    "                # 1.0,\n",
    "                # 1.0,\n",
    "                # 1.0,\n",
    "                # 1.0,\n",
    "                # 1.0,\n",
    "                # 1.0,\n",
    "                # 1.0,\n",
    "                # 1.0,\n",
    "                # 1.0,\n",
    "                # 1.0,\n",
    "                # 1.0,\n",
    "                # 1.0,\n",
    "                # 1.0,\n",
    "                # 1.0,\n",
    "                # 1.0,\n",
    "                # 1.0,\n",
    "                # 1.0,\n",
    "                # 1.0,\n",
    "                # 1.0,\n",
    "                # 1.0,\n",
    "                # 0.1,\n",
    "            ],\n",
    "            loss_weight=2.0,\n",
    "            reduction='mean',\n",
    "            type='CrossEntropyLoss',\n",
    "            use_sigmoid=False),\n",
    "        loss_dice=dict(\n",
    "            activate=True,\n",
    "            eps=1.0,\n",
    "            loss_weight=5.0,\n",
    "            naive_dice=True,\n",
    "            reduction='mean',\n",
    "            type='DiceLoss',\n",
    "            use_sigmoid=True),\n",
    "        loss_mask=dict(\n",
    "            loss_weight=5.0,\n",
    "            reduction='mean',\n",
    "            type='CrossEntropyLoss',\n",
    "            use_sigmoid=True),\n",
    "        num_queries=100,\n",
    "        num_stuff_classes=21, # 53\n",
    "        num_things_classes=14, # 80\n",
    "        num_transformer_feat_level=3,\n",
    "        out_channels=256,\n",
    "        pixel_decoder=dict(\n",
    "            act_cfg=dict(type='ReLU'),\n",
    "            encoder=dict(\n",
    "                layer_cfg=dict(\n",
    "                    ffn_cfg=dict(\n",
    "                        act_cfg=dict(inplace=True, type='ReLU'),\n",
    "                        embed_dims=256,\n",
    "                        feedforward_channels=1024,\n",
    "                        ffn_drop=0.0,\n",
    "                        num_fcs=2),\n",
    "                    self_attn_cfg=dict(\n",
    "                        batch_first=True,\n",
    "                        dropout=0.0,\n",
    "                        embed_dims=256,\n",
    "                        num_heads=8,\n",
    "                        num_levels=3,\n",
    "                        num_points=4)),\n",
    "                num_layers=6),\n",
    "            norm_cfg=dict(num_groups=32, type='GN'),\n",
    "            num_outs=3,\n",
    "            positional_encoding=dict(normalize=True, num_feats=128),\n",
    "            type='MSDeformAttnPixelDecoder'),\n",
    "        positional_encoding=dict(normalize=True, num_feats=128),\n",
    "        strides=[\n",
    "            4,\n",
    "            8,\n",
    "            16,\n",
    "            32,\n",
    "        ],\n",
    "        transformer_decoder=dict(\n",
    "            init_cfg=None,\n",
    "            layer_cfg=dict(\n",
    "                cross_attn_cfg=dict(\n",
    "                    batch_first=True, dropout=0.0, embed_dims=256,\n",
    "                    num_heads=8),\n",
    "                ffn_cfg=dict(\n",
    "                    act_cfg=dict(inplace=True, type='ReLU'),\n",
    "                    embed_dims=256,\n",
    "                    feedforward_channels=2048,\n",
    "                    ffn_drop=0.0,\n",
    "                    num_fcs=2),\n",
    "                self_attn_cfg=dict(\n",
    "                    batch_first=True, dropout=0.0, embed_dims=256,\n",
    "                    num_heads=8)),\n",
    "            num_layers=9,\n",
    "            return_intermediate=True),\n",
    "        type='Mask2FormerHead'),\n",
    "    test_cfg=dict(\n",
    "        filter_low_score=True,\n",
    "        instance_on=True,\n",
    "        iou_thr=0.8,\n",
    "        max_per_image=100,\n",
    "        panoptic_on=True,\n",
    "        semantic_on=False),\n",
    "    train_cfg=dict(\n",
    "        assigner=dict(\n",
    "            match_costs=[\n",
    "                dict(type='ClassificationCost', weight=2.0),\n",
    "                dict(\n",
    "                    type='CrossEntropyLossCost', use_sigmoid=True, weight=5.0),\n",
    "                dict(eps=1.0, pred_act=True, type='DiceCost', weight=5.0),\n",
    "            ],\n",
    "            type='HungarianAssigner'),\n",
    "        importance_sample_ratio=0.75,\n",
    "        num_points=12544,\n",
    "        oversample_ratio=3.0,\n",
    "        sampler=dict(type='MaskPseudoSampler')),\n",
    "    type='Mask2Former')\n",
    "num_classes = 35#133\n",
    "num_stuff_classes = 21#53\n",
    "num_things_classes = 14#80\n",
    "optim_wrapper = dict(\n",
    "    clip_grad=dict(max_norm=0.01, norm_type=2),\n",
    "    optimizer=dict(\n",
    "        betas=(\n",
    "            0.9,\n",
    "            0.999,\n",
    "        ),\n",
    "        eps=1e-08,\n",
    "        lr=0.0001,\n",
    "        type='AdamW',\n",
    "        weight_decay=0.05),\n",
    "    paramwise_cfg=dict(\n",
    "        custom_keys=dict(\n",
    "            backbone=dict(decay_mult=1.0, lr_mult=0.1),\n",
    "            level_embed=dict(decay_mult=0.0, lr_mult=1.0),\n",
    "            query_embed=dict(decay_mult=0.0, lr_mult=1.0),\n",
    "            query_feat=dict(decay_mult=0.0, lr_mult=1.0)),\n",
    "        norm_decay_mult=0.0),\n",
    "    type='OptimWrapper')\n",
    "param_scheduler = dict(\n",
    "    begin=0,\n",
    "    by_epoch=False,\n",
    "    end=368750,\n",
    "    gamma=0.1,\n",
    "    milestones=[\n",
    "        327778,\n",
    "        355092,\n",
    "    ],\n",
    "    type='MultiStepLR')\n",
    "resume = False\n",
    "test_cfg = dict(type='TestLoop')\n",
    "test_dataloader = dict(\n",
    "    batch_size=1,\n",
    "    dataset=dict(\n",
    "        ann_file='annotations/cityscapes_panoptic_val.json',\n",
    "        backend_args=None,\n",
    "        data_prefix=dict(img='leftImg8bit/cityscapes_panoptic_val/', seg='gtFine/cityscapes_panoptic_val/'),\n",
    "        data_root='./data/cityscapes/',\n",
    "        pipeline=[\n",
    "            dict(backend_args=None, type='LoadImageFromFile'),\n",
    "            dict(keep_ratio=True, scale=(\n",
    "                1333,\n",
    "                800,\n",
    "            ), type='Resize'),\n",
    "            dict(backend_args=None, type='LoadPanopticAnnotations'),\n",
    "            dict(\n",
    "                meta_keys=(\n",
    "                    'img_id',\n",
    "                    'img_path',\n",
    "                    'ori_shape',\n",
    "                    'img_shape',\n",
    "                    'scale_factor',\n",
    "                ),\n",
    "                type='PackDetInputs'),\n",
    "        ],\n",
    "        test_mode=True,\n",
    "        type='CityscapesPanopticDataset'),\n",
    "    drop_last=False,\n",
    "    num_workers=2,\n",
    "    persistent_workers=True,\n",
    "    sampler=dict(shuffle=False, type='DefaultSampler'))\n",
    "test_evaluator = [\n",
    "    dict(\n",
    "        ann_file='./data/cityscapes/annotations/cityscapes_panoptic_val.json',\n",
    "        backend_args=None,\n",
    "        seg_prefix='./data/cityscapes/gtFine/cityscapes_panoptic_val',\n",
    "        type='CocoPanopticMetric'),\n",
    "    # dict(\n",
    "    #     ann_file='data/cityscapes/annotations/cityscapes_instances_val.json',\n",
    "    #     backend_args=None,\n",
    "    #     metric=[\n",
    "    #         'bbox',\n",
    "    #         'segm',\n",
    "    #     ],\n",
    "    #     type='CocoMetric'),\n",
    "]\n",
    "test_pipeline = [\n",
    "    dict(backend_args=None, type='LoadImageFromFile'),\n",
    "    dict(keep_ratio=True, scale=(\n",
    "        1333,\n",
    "        800,\n",
    "    ), type='Resize'),\n",
    "    dict(backend_args=None, type='LoadPanopticAnnotations'),\n",
    "    dict(\n",
    "        meta_keys=(\n",
    "            'img_id',\n",
    "            'img_path',\n",
    "            'ori_shape',\n",
    "            'img_shape',\n",
    "            'scale_factor',\n",
    "        ),\n",
    "        type='PackDetInputs'),\n",
    "]\n",
    "train_cfg = dict(\n",
    "    dynamic_intervals=[\n",
    "        (\n",
    "            365001,\n",
    "            368750,\n",
    "        ),\n",
    "    ],\n",
    "    max_iters=1000, #368750\n",
    "    type='IterBasedTrainLoop',\n",
    "    val_interval=5000)\n",
    "train_dataloader = dict(\n",
    "    batch_sampler=dict(type='AspectRatioBatchSampler'),\n",
    "    batch_size=1, # 2\n",
    "    dataset=dict(\n",
    "        ann_file='annotations/cityscapes_panoptic_train.json',\n",
    "        backend_args=None,\n",
    "        data_prefix=dict(\n",
    "            img='leftImg8bit/cityscapes_panoptic_train/', seg='gtFine/cityscapes_panoptic_train/'),\n",
    "        data_root='./data/cityscapes/',\n",
    "        filter_cfg=dict(filter_empty_gt=True, min_size=32),\n",
    "        pipeline=[\n",
    "            dict(backend_args=None, to_float32=True, type='LoadImageFromFile'),\n",
    "            dict(\n",
    "                backend_args=None,\n",
    "                type='LoadPanopticAnnotations',\n",
    "                with_bbox=True,\n",
    "                with_mask=True,\n",
    "                with_seg=True),\n",
    "            dict(prob=0.5, type='RandomFlip'),\n",
    "            dict(\n",
    "                keep_ratio=True,\n",
    "                ratio_range=(\n",
    "                    0.1,\n",
    "                    2.0,\n",
    "                ),\n",
    "                scale=(\n",
    "                    1024,\n",
    "                    1024,\n",
    "                ),\n",
    "                type='RandomResize'),\n",
    "            dict(\n",
    "                allow_negative_crop=True,\n",
    "                crop_size=(\n",
    "                    1024,\n",
    "                    1024,\n",
    "                ),\n",
    "                crop_type='absolute',\n",
    "                recompute_bbox=True,\n",
    "                type='RandomCrop'),\n",
    "            dict(type='PackDetInputs'),\n",
    "        ],\n",
    "        type='CityscapesPanopticDataset'),\n",
    "    num_workers=2,\n",
    "    persistent_workers=True,\n",
    "    sampler=dict(shuffle=True, type='DefaultSampler'))\n",
    "train_pipeline = [\n",
    "    dict(backend_args=None, to_float32=True, type='LoadImageFromFile'),\n",
    "    dict(\n",
    "        backend_args=None,\n",
    "        type='LoadPanopticAnnotations',\n",
    "        with_bbox=True,\n",
    "        with_mask=True,\n",
    "        with_seg=True),\n",
    "    dict(prob=0.5, type='RandomFlip'),\n",
    "    dict(\n",
    "        keep_ratio=True,\n",
    "        ratio_range=(\n",
    "            0.1,\n",
    "            2.0,\n",
    "        ),\n",
    "        scale=(\n",
    "            1024,\n",
    "            1024,\n",
    "        ),\n",
    "        type='RandomResize'),\n",
    "    dict(\n",
    "        allow_negative_crop=True,\n",
    "        crop_size=(\n",
    "            1024,\n",
    "            1024,\n",
    "        ),\n",
    "        crop_type='absolute',\n",
    "        recompute_bbox=True,\n",
    "        type='RandomCrop'),\n",
    "    dict(type='PackDetInputs'),\n",
    "]\n",
    "val_cfg = dict(type='ValLoop')\n",
    "val_dataloader = dict(\n",
    "    batch_size=1,\n",
    "    dataset=dict(\n",
    "        ann_file='annotations/cityscapes_panoptic_val.json',\n",
    "        backend_args=None,\n",
    "        data_prefix=dict(img='leftImg8bit/cityscapes_panoptic_val/', seg='gtFine/cityscapes_panoptic_val/'),\n",
    "        data_root='./data/cityscapes/',\n",
    "        pipeline=[\n",
    "            dict(backend_args=None, type='LoadImageFromFile'),\n",
    "            dict(keep_ratio=True, scale=(\n",
    "                1333,\n",
    "                800,\n",
    "            ), type='Resize'),\n",
    "            dict(backend_args=None, type='LoadPanopticAnnotations'),\n",
    "            dict(\n",
    "                meta_keys=(\n",
    "                    'img_id',\n",
    "                    'img_path',\n",
    "                    'ori_shape',\n",
    "                    'img_shape',\n",
    "                    'scale_factor',\n",
    "                ),\n",
    "                type='PackDetInputs'),\n",
    "        ],\n",
    "        test_mode=True,\n",
    "        type='CityscapesPanopticDataset'),\n",
    "    drop_last=False,\n",
    "    num_workers=2,\n",
    "    persistent_workers=True,\n",
    "    sampler=dict(shuffle=False, type='DefaultSampler'))\n",
    "val_evaluator = [\n",
    "    dict(\n",
    "        ann_file='./data/cityscapes/annotations/cityscapes_panoptic_val.json',\n",
    "        backend_args=None,\n",
    "        seg_prefix='./data/cityscapes/gtFine/cityscapes_panoptic_val/',\n",
    "        type='CocoPanopticMetric'),\n",
    "    # dict(\n",
    "    #     ann_file='data/cityscapes/annotations/cityscapes_instances_val.json',\n",
    "    #     backend_args=None,\n",
    "    #     metric=[\n",
    "    #         'bbox',\n",
    "    #         'segm',\n",
    "    #     ],\n",
    "    #     type='CocoMetric'),\n",
    "]\n",
    "vis_backends = [\n",
    "    dict(type='LocalVisBackend'),\n",
    "]\n",
    "visualizer = dict(\n",
    "    name='visualizer',\n",
    "    type='DetLocalVisualizer',\n",
    "    vis_backends=[\n",
    "        dict(type='LocalVisBackend'),\n",
    "    ])\n"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "D9LEGKLccCkp",
    "outputId": "c9400c8c-191a-4ecf-e1d4-74fd90b6184e"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "%%writefile /content/mmdetection/mmdet/datasets/cityscapes_panoptic_dataset.py\n",
    "from mmdet.registry import DATASETS\n",
    "from .api_wrappers import COCOPanoptic\n",
    "from .coco_panoptic import CocoPanopticDataset\n",
    "\n",
    "\n",
    "@DATASETS.register_module()\n",
    "class CityscapesPanopticDataset(CocoPanopticDataset):\n",
    "\n",
    "    METAINFO = {\n",
    "        'classes':\n",
    "        (\n",
    "         'unlabeled', 'ego vehicle', 'rectification border', 'out of roi', 'static', 'dynamic',\n",
    "         'ground', 'road', 'sidewalk', 'parking', 'rail track', 'building', 'wall', 'fence',\n",
    "         'guard rail', 'bridge', 'tunnel', 'pole', 'polegroup', 'traffic light', 'traffic sign',\n",
    "         'vegetation', 'terrain', 'sky', 'person', 'rider', 'car', 'truck', 'bus', 'caravan',\n",
    "         'trailer', 'train', 'motorcycle', 'bicycle', 'license plate'\n",
    "        ),\n",
    "        'thing_classes': (\n",
    "          'ego vehicle', 'static', 'dynamic', 'person', 'rider', 'car', 'truck', 'bus',\n",
    "          'caravan', 'trailer', 'train', 'motorcycle', 'bicycle', 'license plate'\n",
    "        ),\n",
    "        'stuff_classes': (\n",
    "          'unlabeled', 'rectification border', 'out of roi', 'ground', 'road', 'sidewalk',\n",
    "          'parking', 'rail track', 'building', 'wall', 'fence', 'guard rail', 'bridge',\n",
    "          'tunnel', 'pole', 'polegroup', 'traffic light', 'traffic sign', 'vegetation',\n",
    "          'terrain', 'sky'\n",
    "        ),\n",
    "        'palette':\n",
    "        [\n",
    "         (0,  0,  0), (0,  0,  0), (0,  0,  0), (0,  0,  0), (0,  0,  0), (111, 74,  0),\n",
    "         (81,  0, 81), (128, 64, 128), (244, 35, 232), (250, 170, 160), (230, 150, 140),\n",
    "         (70, 70, 70), (102, 102, 156), (190, 153, 153), (180, 165, 180), (150, 100, 100),\n",
    "         (150, 120, 90), (153, 153, 153), (153, 153, 153), (250, 170, 30), (220, 220,  0),\n",
    "         (107, 142, 35), (152, 251, 152), (70, 130, 180), (220, 20, 60), (255,  0,  0),\n",
    "         (0,  0, 142), (0,  0, 70), (0, 60, 100), (0,  0, 90), (0,  0, 110), (0, 80, 100),\n",
    "         (0,  0, 230), (119, 11, 32), (0,  0, 142)\n",
    "        ]\n",
    "    }\n",
    "    COCOAPI = COCOPanoptic\n",
    "    # ann_id is not unique in coco panoptic dataset.\n",
    "    ANN_ID_UNIQUE = False\n"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "O-I9wI1m6Qhb",
    "outputId": "73c2cddc-237b-4f0d-8e25-0a84fc156961"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "%%writefile /content/mmdetection/mmdet/datasets/__init__.py\n",
    "# Copyright (c) OpenMMLab. All rights reserved.\n",
    "from .ade20k import (ADE20KInstanceDataset, ADE20KPanopticDataset,\n",
    "                     ADE20KSegDataset)\n",
    "from .base_det_dataset import BaseDetDataset\n",
    "from .base_semseg_dataset import BaseSegDataset\n",
    "from .base_video_dataset import BaseVideoDataset\n",
    "from .cityscapes import CityscapesDataset\n",
    "from .coco import CocoDataset\n",
    "from .coco_caption import CocoCaptionDataset\n",
    "from .coco_panoptic import CocoPanopticDataset\n",
    "from .coco_semantic import CocoSegDataset\n",
    "from .crowdhuman import CrowdHumanDataset\n",
    "from .dataset_wrappers import ConcatDataset, MultiImageMixDataset\n",
    "from .deepfashion import DeepFashionDataset\n",
    "from .dsdl import DSDLDetDataset\n",
    "from .isaid import iSAIDDataset\n",
    "from .lvis import LVISDataset, LVISV1Dataset, LVISV05Dataset\n",
    "from .mot_challenge_dataset import MOTChallengeDataset\n",
    "from .objects365 import Objects365V1Dataset, Objects365V2Dataset\n",
    "from .openimages import OpenImagesChallengeDataset, OpenImagesDataset\n",
    "from .refcoco import RefCocoDataset\n",
    "from .reid_dataset import ReIDDataset\n",
    "from .samplers import (AspectRatioBatchSampler, ClassAwareSampler,\n",
    "                       GroupMultiSourceSampler, MultiSourceSampler,\n",
    "                       TrackAspectRatioBatchSampler, TrackImgSampler)\n",
    "from .utils import get_loading_pipeline\n",
    "from .v3det import V3DetDataset\n",
    "from .voc import VOCDataset\n",
    "from .wider_face import WIDERFaceDataset\n",
    "from .xml_style import XMLDataset\n",
    "from .youtube_vis_dataset import YouTubeVISDataset\n",
    "from .cityscapes_panoptic_dataset import CityscapesPanopticDataset\n",
    "\n",
    "__all__ = [\n",
    "    'XMLDataset', 'CocoDataset', 'DeepFashionDataset', 'VOCDataset',\n",
    "    'CityscapesDataset', 'LVISDataset', 'LVISV05Dataset', 'LVISV1Dataset',\n",
    "    'WIDERFaceDataset', 'get_loading_pipeline', 'CocoPanopticDataset',\n",
    "    'MultiImageMixDataset', 'OpenImagesDataset', 'OpenImagesChallengeDataset',\n",
    "    'AspectRatioBatchSampler', 'ClassAwareSampler', 'MultiSourceSampler',\n",
    "    'GroupMultiSourceSampler', 'BaseDetDataset', 'CrowdHumanDataset',\n",
    "    'Objects365V1Dataset', 'Objects365V2Dataset', 'DSDLDetDataset',\n",
    "    'BaseVideoDataset', 'MOTChallengeDataset', 'TrackImgSampler',\n",
    "    'ReIDDataset', 'YouTubeVISDataset', 'TrackAspectRatioBatchSampler',\n",
    "    'ADE20KPanopticDataset', 'CocoCaptionDataset', 'RefCocoDataset',\n",
    "    'BaseSegDataset', 'ADE20KSegDataset', 'CocoSegDataset',\n",
    "    'ADE20KInstanceDataset', 'iSAIDDataset', 'V3DetDataset', 'ConcatDataset', 'CityscapesPanopticDataset'\n",
    "]"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "cmDYHQEv6G8p",
    "outputId": "374d5cbc-dc30-4b28-ae07-f351ee2ab145"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "import locale\n",
    "\n",
    "\n",
    "locale.getpreferredencoding = lambda: \"UTF-8\""
   ],
   "metadata": {
    "id": "r0RunouO58Jv"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "import torch\n",
    "\n",
    "\n",
    "with torch.no_grad():\n",
    "    torch.cuda.empty_cache()\n",
    "!nvidia-smi"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "fOSaTtBjLgzH",
    "outputId": "329a4d45-0d9d-4c0a-eb96-1d7015cac98e"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "!python mmdetection/tools/train.py mask2former_r50_8xb2-lsj-50e_cityscapes-panoptic_train.py"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "g18E87b7pSzl",
    "outputId": "d7405d38-1324-49ef-a61c-a196361da76f"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "# !rm -rf /content/outputs/"
   ],
   "metadata": {
    "id": "AECmWi_tB3fh"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "!python /content/mmdetection/demo/image_demo.py \\\n",
    "\t\t/content/mmdetection/demo/demo.jpg \\\n",
    "        /content/work_dirs/mask2former_r50_8xb2-lsj-50e_cityscapes-panoptic_train/mask2former_r50_8xb2-lsj-50e_cityscapes-panoptic_train.py \\\n",
    "        --weights /content/work_dirs/mask2former_r50_8xb2-lsj-50e_cityscapes-panoptic_train/iter_1000.pth \\\n",
    "        --device cpu"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "72LkJ-38pSw8",
    "outputId": "1cb4886a-94bd-4317-cf86-4ee92940fdf4"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "from IPython.display import Image\n",
    "\n",
    "\n",
    "Image(\"outputs/vis/demo.jpg\")"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 444
    },
    "id": "ARAQWeAKpSup",
    "outputId": "cc388221-d3e2-469c-8e30-1a7edc01ccd3"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "!python /content/mmdetection/demo/image_demo.py \\\n",
    "\t\t/content/data/cityscapes/leftImg8bit/train/krefeld/krefeld_000000_000108_leftImg8bit.png \\\n",
    "        /content/work_dirs/mask2former_r50_8xb2-lsj-50e_cityscapes-panoptic_train/mask2former_r50_8xb2-lsj-50e_cityscapes-panoptic_train.py \\\n",
    "        --weights /content/work_dirs/mask2former_r50_8xb2-lsj-50e_cityscapes-panoptic_train/iter_1000.pth \\\n",
    "        --device cpu"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "iC5RQSWVpSsD",
    "outputId": "d95f79b4-11d1-4c4c-a180-ff9c2f521508"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "from IPython.display import Image\n",
    "\n",
    "\n",
    "Image(\"outputs/vis/krefeld_000000_000108_leftImg8bit.png\")"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 559
    },
    "id": "LNXEBNTzpSpr",
    "outputId": "8316f537-609d-4355-c505-e20173a00ede"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "!python mmdetection/tools/test.py \\\n",
    "        /content/work_dirs/mask2former_r50_8xb2-lsj-50e_cityscapes-panoptic_train/mask2former_r50_8xb2-lsj-50e_cityscapes-panoptic_train.py \\\n",
    "        /content/work_dirs/mask2former_r50_8xb2-lsj-50e_cityscapes-panoptic_train/iter_1000.pth"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "qHAtpPBTpSnI",
    "outputId": "3ba26dbd-f058-46ad-89a3-01d74d6e3188"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [],
   "metadata": {
    "id": "9pJzBFpqpSku"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [],
   "metadata": {
    "id": "tfiH-it2pSia"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [],
   "metadata": {
    "id": "ehhGFAiipSgA"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [],
   "metadata": {
    "id": "MA2no63JpSdb"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [],
   "metadata": {
    "id": "ikapKkgEpSa2"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [],
   "metadata": {
    "id": "r4rt6gZjpSYe"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [],
   "metadata": {
    "id": "VknWCuFqpSVn"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [],
   "metadata": {
    "id": "iPlwCQBmpSTR"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [],
   "metadata": {
    "id": "Kf5_m44jpSQp"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [],
   "metadata": {
    "id": "cJqvt6bmpSN2"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [],
   "metadata": {
    "id": "zsg1NvlipSKt"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "%cd /content\n",
    "!python mmdetection/tools/train.py \\\n",
    "        mmdetection/configs/mask2former/mask2former_r50_8xb2-lsj-50e_coco-panoptic.py"
   ],
   "metadata": {
    "id": "iAg9M52upSID"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "3td9tPjv90Ri",
    "outputId": "6e9d7663-687f-43f1-b533-c27194f84b8e"
   },
   "outputs": [],
   "source": [
    "%cd /content\n",
    "\n",
    "%rm -rf data"
   ]
  },
  {
   "cell_type": "code",
   "source": [],
   "metadata": {
    "id": "XPAoz57z0OtV"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "kpOrg6va9MeK",
    "outputId": "2f1d7569-ee66-4b73-919f-2595fb969d75"
   },
   "outputs": [],
   "source": [
    "%cd /content\n",
    "\n",
    "%mkdir data\n",
    "%cd data\n",
    "%mkdir coco\n",
    "%cd coco\n",
    "%mkdir images\n",
    "%cd images\n",
    "\n",
    "# !wget -c http://images.cocodataset.org/zips/train2017.zip\n",
    "!wget -c http://images.cocodataset.org/zips/val2017.zip\n",
    "!wget -c http://images.cocodataset.org/zips/test2017.zip\n",
    "# !wget -c http://images.cocodataset.org/zips/unlabeled2017.zip\n",
    "\n",
    "# !unzip train2017.zip\n",
    "!unzip val2017.zip\n",
    "!unzip test2017.zip\n",
    "# !unzip unlabeled2017.zip\n",
    "\n",
    "# %rm train2017.zip\n",
    "%rm val2017.zip\n",
    "%rm test2017.zip\n",
    "# %rm unlabeled2017.zip\n",
    "\n",
    "%cd ../\n",
    "!wget -c http://images.cocodataset.org/annotations/annotations_trainval2017.zip\n",
    "!wget -c http://images.cocodataset.org/annotations/stuff_annotations_trainval2017.zip\n",
    "!wget -c http://images.cocodataset.org/annotations/image_info_test2017.zip\n",
    "!wget -c http://images.cocodataset.org/annotations/image_info_unlabeled2017.zip\n",
    "!wget http://images.cocodataset.org/annotations/panoptic_annotations_trainval2017.zip\n",
    "\n",
    "!unzip annotations_trainval2017.zip\n",
    "!unzip stuff_annotations_trainval2017.zip\n",
    "!unzip image_info_test2017.zip\n",
    "!unzip image_info_unlabeled2017.zip\n",
    "!unzip panoptic_annotations_trainval2017.zip\n",
    "\n",
    "%rm annotations_trainval2017.zip\n",
    "%rm stuff_annotations_trainval2017.zip\n",
    "%rm image_info_test2017.zip\n",
    "%rm image_info_unlabeled2017.zip\n",
    "%rm panoptic_annotations_trainval2017.zip"
   ]
  },
  {
   "cell_type": "code",
   "source": [],
   "metadata": {
    "id": "SYx1CN6hplcU"
   },
   "execution_count": null,
   "outputs": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "provenance": [],
   "gpuType": "T4"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "74044288d8584b2aa53f93c507ffe615": {
     "model_module": "@jupyter-widgets/output",
     "model_name": "OutputModel",
     "model_module_version": "1.0.0",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/output",
      "_model_module_version": "1.0.0",
      "_model_name": "OutputModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/output",
      "_view_module_version": "1.0.0",
      "_view_name": "OutputView",
      "layout": "IPY_MODEL_619f1b131b6041ca91ed77504396de37",
      "msg_id": "",
      "outputs": [
       {
        "output_type": "display_data",
        "data": {
         "text/plain": "Inference \u001B[38;2;123;51;77m\u001B[0m\u001B[38;2;97;53;69m\u001B[0m\u001B[38;2;76;56;63m\u001B[0m\u001B[38;2;62;57;59m\u001B[0m\u001B[38;2;58;58;58m\u001B[0m\u001B[38;2;62;57;59m\u001B[0m\u001B[38;2;76;56;63m\u001B[0m\u001B[38;2;97;53;69m\u001B[0m\u001B[38;2;123;51;77m\u001B[0m\u001B[38;2;153;48;86m\u001B[0m\u001B[38;2;183;44;94m\u001B[0m\u001B[38;2;209;42;102m\u001B[0m\u001B[38;2;230;39;108m\u001B[0m\u001B[38;2;244;38;112m\u001B[0m\u001B[38;2;249;38;114m\u001B[0m\u001B[38;2;244;38;112m\u001B[0m\u001B[38;2;230;39;108m\u001B[0m\u001B[38;2;209;42;102m\u001B[0m\u001B[38;2;183;44;94m\u001B[0m\u001B[38;2;153;48;86m\u001B[0m\u001B[38;2;123;51;77m\u001B[0m\u001B[38;2;97;53;69m\u001B[0m\u001B[38;2;76;56;63m\u001B[0m\u001B[38;2;62;57;59m\u001B[0m\u001B[38;2;58;58;58m\u001B[0m\u001B[38;2;62;57;59m\u001B[0m\u001B[38;2;76;56;63m\u001B[0m\u001B[38;2;97;53;69m\u001B[0m\u001B[38;2;123;51;77m\u001B[0m\u001B[38;2;153;48;86m\u001B[0m\u001B[38;2;183;44;94m\u001B[0m\u001B[38;2;209;42;102m\u001B[0m\u001B[38;2;230;39;108m\u001B[0m\u001B[38;2;244;38;112m\u001B[0m\u001B[38;2;249;38;114m\u001B[0m\u001B[38;2;244;38;112m\u001B[0m\u001B[38;2;230;39;108m\u001B[0m\u001B[38;2;209;42;102m\u001B[0m\u001B[38;2;183;44;94m\u001B[0m\u001B[38;2;153;48;86m\u001B[0m  \u001B[36m \u001B[0m\n",
         "text/html": "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Inference <span style=\"color: #7b334d; text-decoration-color: #7b334d\"></span><span style=\"color: #613545; text-decoration-color: #613545\"></span><span style=\"color: #4c383f; text-decoration-color: #4c383f\"></span><span style=\"color: #3e393b; text-decoration-color: #3e393b\"></span><span style=\"color: #3a3a3a; text-decoration-color: #3a3a3a\"></span><span style=\"color: #3e393b; text-decoration-color: #3e393b\"></span><span style=\"color: #4c383f; text-decoration-color: #4c383f\"></span><span style=\"color: #613545; text-decoration-color: #613545\"></span><span style=\"color: #7b334d; text-decoration-color: #7b334d\"></span><span style=\"color: #993056; text-decoration-color: #993056\"></span><span style=\"color: #b72c5e; text-decoration-color: #b72c5e\"></span><span style=\"color: #d12a66; text-decoration-color: #d12a66\"></span><span style=\"color: #e6276c; text-decoration-color: #e6276c\"></span><span style=\"color: #f42670; text-decoration-color: #f42670\"></span><span style=\"color: #f92672; text-decoration-color: #f92672\"></span><span style=\"color: #f42670; text-decoration-color: #f42670\"></span><span style=\"color: #e6276c; text-decoration-color: #e6276c\"></span><span style=\"color: #d12a66; text-decoration-color: #d12a66\"></span><span style=\"color: #b72c5e; text-decoration-color: #b72c5e\"></span><span style=\"color: #993056; text-decoration-color: #993056\"></span><span style=\"color: #7b334d; text-decoration-color: #7b334d\"></span><span style=\"color: #613545; text-decoration-color: #613545\"></span><span style=\"color: #4c383f; text-decoration-color: #4c383f\"></span><span style=\"color: #3e393b; text-decoration-color: #3e393b\"></span><span style=\"color: #3a3a3a; text-decoration-color: #3a3a3a\"></span><span style=\"color: #3e393b; text-decoration-color: #3e393b\"></span><span style=\"color: #4c383f; text-decoration-color: #4c383f\"></span><span style=\"color: #613545; text-decoration-color: #613545\"></span><span style=\"color: #7b334d; text-decoration-color: #7b334d\"></span><span style=\"color: #993056; text-decoration-color: #993056\"></span><span style=\"color: #b72c5e; text-decoration-color: #b72c5e\"></span><span style=\"color: #d12a66; text-decoration-color: #d12a66\"></span><span style=\"color: #e6276c; text-decoration-color: #e6276c\"></span><span style=\"color: #f42670; text-decoration-color: #f42670\"></span><span style=\"color: #f92672; text-decoration-color: #f92672\"></span><span style=\"color: #f42670; text-decoration-color: #f42670\"></span><span style=\"color: #e6276c; text-decoration-color: #e6276c\"></span><span style=\"color: #d12a66; text-decoration-color: #d12a66\"></span><span style=\"color: #b72c5e; text-decoration-color: #b72c5e\"></span><span style=\"color: #993056; text-decoration-color: #993056\"></span>  <span style=\"color: #008080; text-decoration-color: #008080\"> </span>\n</pre>\n"
        },
        "metadata": {}
       }
      ]
     }
    },
    "619f1b131b6041ca91ed77504396de37": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "model_module_version": "1.2.0",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
